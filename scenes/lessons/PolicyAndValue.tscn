[gd_scene load_steps=9 format=3 uid="uid://dsu3y635nr3tu"]

[ext_resource type="Script" path="res://scenes/scripts/Lesson.gd" id="1_4f2dx"]
[ext_resource type="Theme" uid="uid://dhymcf16h2rcx" path="res://resources/themes/impact_theme.tres" id="2_ol23v"]
[ext_resource type="Theme" uid="uid://boy78iwy5tcum" path="res://resources/themes/lesson_theme.tres" id="3_ty2qw"]
[ext_resource type="Texture2D" uid="uid://c3uxuaonqpmou" path="res://resources/lessons/images/policyview.png" id="4_t551r"]
[ext_resource type="Texture2D" uid="uid://vbl33o0ce0fa" path="res://resources/lessons/images/valueview.png" id="5_5kn5t"]
[ext_resource type="Theme" uid="uid://dpvfhrd6522wp" path="res://resources/themes/main_theme.tres" id="7_vvgdh"]
[ext_resource type="FontFile" uid="uid://baq7wadp53op4" path="res://resources/fonts/Ranchers-v1/Ranchers-Regular.ttf" id="8_pwycl"]
[ext_resource type="Script" path="res://addons/jam_essentials/scenes/scripts/TransitionButton.gd" id="9_gc07j"]

[node name="Lesson" type="Polygon2D"]
position = Vector2(528, 0)
polygon = PackedVector2Array(448, -16, 480, 560, 976, 560, 976, -16)
script = ExtResource("1_4f2dx")

[node name="LessonShadow" type="Polygon2D" parent="."]
show_behind_parent = true
position = Vector2(-7, 0)
color = Color(0, 0, 0, 1)
polygon = PackedVector2Array(448, -16, 480, 560, 976, 560, 976, -16)

[node name="Lessons" type="ScrollContainer" parent="."]
clip_contents = false
offset_left = 512.0
offset_top = 16.0
offset_right = 944.0
offset_bottom = 528.0
mouse_filter = 0
theme = ExtResource("7_vvgdh")
vertical_scroll_mode = 2

[node name="VBox" type="VBoxContainer" parent="Lessons"]
custom_minimum_size = Vector2(424, 0)
layout_mode = 2
alignment = 1

[node name="Title" type="RichTextLabel" parent="Lessons/VBox"]
clip_contents = false
layout_mode = 2
mouse_filter = 1
theme = ExtResource("2_ol23v")
theme_override_font_sizes/normal_font_size = 32
bbcode_enabled = true
text = "[center]Policy and Value"
fit_content = true

[node name="1" type="RichTextLabel" parent="Lessons/VBox"]
clip_contents = false
layout_mode = 2
mouse_filter = 1
theme = ExtResource("3_ty2qw")
bbcode_enabled = true
text = "Now that we understand our environment, it's time to model exactly what we want our agent to learn within it. Our final objective is to maximize the reward gained over time in our environment. Since the only way we can interact with our environment is through the selection of actions, [wave]we want to find the selection of actions that will wield the greatest reward over time[/wave].

The way we model this mathematically is through a function called a [wave]policy[/wave], represented by the letter pi. Basically, a policy models the way our agent selects actions. As such [wave]for each state, our policy tells us what action we should take[/wave]. Ultimately, we want to find an optimal policy, one that always gives us the action that will result in the highest reward over time.

While running the sandbox, you can hold W to get a view of the agent's current policy. Don't worry too much about how it's calculated for now, and know that while learning the agent may take actions that are different from its policy for the sake of trying different things to see what works better."
fit_content = true

[node name="2" type="TextureRect" parent="Lessons/VBox"]
layout_mode = 2
texture = ExtResource("4_t551r")
stretch_mode = 3

[node name="3" type="RichTextLabel" parent="Lessons/VBox"]
clip_contents = false
layout_mode = 2
mouse_filter = 1
theme = ExtResource("3_ty2qw")
bbcode_enabled = true
text = "One way we learn policies is through the use of[wave] state value functions[/wave]. Essentially, they give us a value for each state the agent can be in, which represents how much reward we can expect to gain in the long run from being in each state. It follows, then, that states close to the goal have a higher value than states farther away from it.

State value functions presume that we have a policy that we're working with, since it's impossible to determine how good being in a state is without knowing what we're gonna do once we're in it.

On the other hand, [wave]action value functions[/wave] provide a value not for each state but for each state-action pair. In other words, in any given state we would have a different value for performing each action. This gives us a basic idea for choosing a policy, for each state, simply choose the action with the most value according to our action value function!

While running the sandbox, you can hold Q to get a view of the agent's current value function. Behind the scenes, we're using an action value function. As such, for each state, the value shown is the value of the best action in that state."
fit_content = true

[node name="4" type="TextureRect" parent="Lessons/VBox"]
layout_mode = 2
texture = ExtResource("5_5kn5t")
stretch_mode = 3

[node name="5" type="RichTextLabel" parent="Lessons/VBox"]
clip_contents = false
layout_mode = 2
mouse_filter = 1
theme = ExtResource("3_ty2qw")
bbcode_enabled = true
text = "Since we can determine a good policy given an accurate value function, we only need to find a way to learn an accurate value function. In other words, how do we know the expected future reward for each state or state-action pair?

For now, you can hop on the sandbox to look at evolving policies and value functions.

- Notice where the value functions have the highest and lowest values
- Can you see the way the policy depends on the value of the adjacent states?"
fit_content = true

[node name="Sandbox" type="Button" parent="Lessons/VBox"]
layout_mode = 2
theme = ExtResource("7_vvgdh")
theme_override_colors/font_hover_color = Color(1, 0.713726, 0, 1)
theme_override_fonts/font = ExtResource("8_pwycl")
text = "Experiment!"
flat = true
script = ExtResource("9_gc07j")
transition_path = "res://scenes/experiments/PolicyAndValue.tscn"
